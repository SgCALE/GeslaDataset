{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example usage\n",
    "\n",
    "## Initialize a GeslaDataset object\n",
    "Place the `gesla.py` file in your working directory (or elsewhere on your path), and import the `GeslaDataset` class. Selecting and loading data files requires paths to the metadata .csv file and the directory containing the data files. Initialize a `GeslaDataset` object with these paths as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gesla import GeslaDataset\n",
    "\n",
    "meta_file = \"../GESLAv3/GESLA3_ALL.csv\"\n",
    "data_path = \"../GESLAv3/data/\"\n",
    "\n",
    "g3 = GeslaDataset(meta_file=meta_file, data_path=data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from a single file\n",
    "If you want to work with data from a single record, and you know the filename you want, use the function `file_to_pandas` as follows. The function returns a `pandas.DataFrame` with data and flags, and a `pandas.Series` containing metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sea_level</th>\n",
       "      <th>qc_flag</th>\n",
       "      <th>use_flag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date_time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1971-06-09 05:00:00</th>\n",
       "      <td>2.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-06-09 06:00:00</th>\n",
       "      <td>1.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-06-09 07:00:00</th>\n",
       "      <td>1.29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-06-09 08:00:00</th>\n",
       "      <td>0.79</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-06-09 09:00:00</th>\n",
       "      <td>0.63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-10-26 00:00:00</th>\n",
       "      <td>0.86</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-10-26 01:00:00</th>\n",
       "      <td>0.65</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-10-26 02:00:00</th>\n",
       "      <td>0.99</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-10-26 03:00:00</th>\n",
       "      <td>1.42</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-10-26 04:00:00</th>\n",
       "      <td>1.84</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3336 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     sea_level  qc_flag  use_flag\n",
       "date_time                                        \n",
       "1971-06-09 05:00:00       2.29        1         1\n",
       "1971-06-09 06:00:00       1.79        1         1\n",
       "1971-06-09 07:00:00       1.29        1         1\n",
       "1971-06-09 08:00:00       0.79        1         1\n",
       "1971-06-09 09:00:00       0.63        1         1\n",
       "...                        ...      ...       ...\n",
       "1971-10-26 00:00:00       0.86        1         1\n",
       "1971-10-26 01:00:00       0.65        1         1\n",
       "1971-10-26 02:00:00       0.99        1         1\n",
       "1971-10-26 03:00:00       1.42        1         1\n",
       "1971-10-26 04:00:00       1.84        1         1\n",
       "\n",
       "[3336 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = \"abrams_river-380-canada-meds\"\n",
    "data, meta = g3.file_to_pandas(filename)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from a list of files\n",
    "If you want to work with data from multiple files, and you know the filenames you want, use the function `files_to_xarray` as follows. The function returns a `xarray.Dataset` object containing data, flags, and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:                  (date_time: 289251, station: 4)\n",
      "Coordinates:\n",
      "  * station                  (station) int64 0 1 2 3\n",
      "  * date_time                (date_time) datetime64[ns] 1971-06-09T05:00:00 ....\n",
      "Data variables:\n",
      "    sea_level                (station, date_time) float64 2.29 1.79 ... nan nan\n",
      "    qc_flag                  (station, date_time) float64 1.0 1.0 ... nan nan\n",
      "    use_flag                 (station, date_time) float64 1.0 1.0 ... nan nan\n",
      "    site_name                (station) object 'Acajutla' ... 'Abrams_River'\n",
      "    site_code                (station) object '082C' 'HD26' '8761494' '380'\n",
      "    country                  (station) object 'El_Salvador' 'Japan' ... 'Canada'\n",
      "    contributor_abbreviated  (station) object 'UHSLC' 'JODC_JCG' 'NOAA' 'MEDS'\n",
      "    contributor_full         (station) object 'University of Hawaii Sea Level...\n",
      "    contributor_website      (station) object 'https://uhslc.soest.hawaii.edu...\n",
      "    contributor_contact      (station) object 'philiprt@hawaii.edu' ... 'Jenn...\n",
      "    orginator                (station) object ' University of Hawaii Sea Leve...\n",
      "    originator_website       (station) object 'Unspecified' ... 'https://isdm...\n",
      "    originator_contact       (station) object 'Unspecified' ... 'Jenny.Chiu@d...\n",
      "    latitude                 (station) float64 13.57 41.44 29.57 43.83\n",
      "    longitude                (station) float64 -89.84 140.2 -89.81 -65.95\n",
      "    coordinate_system        (station) object 'Unspecified' ... 'Unspecified'\n",
      "    start_date_time          (station) datetime64[ns] 2010-08-19T21:00:00 ......\n",
      "    end_date_time            (station) datetime64[ns] 2018-12-31T23:00:00 ......\n",
      "    number_of_years          (station) int64 9 25 4 1\n",
      "    time_zone_hours          (station) int64 0 0 0 0\n",
      "    datum_information        (station) object 'Unspecified' ... 'Chart Datum ...\n",
      "    instrument               (station) object 'Unspecified' ... 'Unspecified'\n",
      "    precision                (station) object 'Unspecified' ... 'Unspecified'\n",
      "    null_value               (station) float64 -100.0 -100.0 -100.0 -100.0\n",
      "    gauge_type               (station) object 'Coastal' 'Coastal' ... 'Coastal'\n",
      "    overall_record_quality   (station) object 'No obvious issues' ... 'No obv...\n",
      "    filename                 (station) object 'acajutla-082c-el_salvador-uhsl...\n"
     ]
    }
   ],
   "source": [
    "filenames = [\n",
    "    \"abrams_river-380-canada-meds\",\n",
    "    \"acajutla-082c-el_salvador-uhslc\", \n",
    "    \"yoshioka-hd26-japan-jodc_jcg\", \n",
    "    \"west_point_a_la_hache-8761494-united_states_of_america_the-noaa\",\n",
    "]\n",
    "xr_dataset = g3.files_to_xarray(filenames)\n",
    "print(xr_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from the N closest records to a lat/lon location\n",
    "Load data from records close to a particular location using the function `load_N_closest` as follows. Provide a lat/lon location and the number of desired records. The function returns a `xarray.Dataset` object containing data, flags, and metadata.  \n",
    "\n",
    "Note the `UserWarning` that occurs when duplicate timestamps are encountered. The function `file_to_pandas` used to read each individual file keeps only the first of any duplicate timestamps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yarmouth' 'Lower_Wedgeport' 'Pinkney_Point' 'Abbotts_Harbour'\n",
      " 'Clarks_Harbour' 'Woods_Harbour' 'Tusket' 'Abrams_River' 'Flat_Island'\n",
      " 'Wedgeport']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/phil/Dropbox (Personal)/Research/Data/TideGaugeSets/GESLAv3/GeslaDataset/gesla.py:76: UserWarning: Duplicate timestamps in file yarmouth-365-canada-meds were removed.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "data = g3.load_N_closest(lat=43.83, lon=-65.95, N=10)\n",
    "print(data.site_name.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data from the records in a lat/lon range\n",
    "Load data from records in a rectangular lat/lon range using the function `load_lat_lon_range` as follows. Provide lat/lon extents of the range. The function returns a `xarray.Dataset` object containing data, flags, and metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Honolulu_Hawaii' 'Hilo_Hawaii' 'Midway' 'Johnston' 'Kahului'\n",
      " 'Nawiliwili' 'Mokuoloe' 'French_Frigate' 'Kawaihae' 'French_Frigate'\n",
      " 'Barbers_Point_HI' 'Honolulu_Kewalo' 'Port_Allen' 'Kaumalapau_HI'\n",
      " 'Honolulu_Hawaii' 'Honolulu_Pier_45' 'Honolulu' 'Hilo' 'Nawiliwili'\n",
      " 'Sand_Island' 'Kahului' 'Mokuoloe' 'Kawaihae' 'Johnston_Atoll'\n",
      " 'Port_Allen' 'Kaumalapau_Harbor' 'Kaunakakai_Harbor' 'Laiemaloo'\n",
      " 'Fort_Kamehameha' 'Ford_Island']\n"
     ]
    }
   ],
   "source": [
    "south_lat = 15\n",
    "north_lat = 30\n",
    "west_lon = -180\n",
    "east_lon = -140\n",
    "\n",
    "data = g3.load_lat_lon_range(\n",
    "    south_lat=south_lat,\n",
    "    north_lat=north_lat,\n",
    "    west_lon=west_lon,\n",
    "    east_lon=east_lon,\n",
    ")\n",
    "print(data.site_name.values)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4b2458d0610a23fbd5c707a25149dc9218000ef165f906d82c15727d18cbe22b"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
